{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Unpivoting Columns \n",
    "Slug: unpivoting_columns \n",
    "Summary: Reverse pivot columns to be added as new rows in a dataframe. \n",
    "Date: 2016-11-27 12:00 \n",
    "Category: wrangling_data \n",
    "Tags: \n",
    "Authors: Nate Hall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://nbviewer.jupyter.org/github/nathan-hall/nathan-hall.github.io/blob/pelican/content/wrangling_data/editing_column_names.ipynb\" target=\"_blank\">Link to the full jupyter notebook.</a><br/>\n",
    "<a href=\"http://nbviewer.jupyter.org/github/nathan-hall/nathan-hall.github.io/blob/pelican/content/wrangling_data/editing_column_names_code.ipynb\" target=\"_blank\">Link to the code only jupyter notebook.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We'll be using the billboard hot 100 dataset as the example.\n",
    "- We wanted to get the dataset to have rows representing the lowest level of data possible.\n",
    "- <a href=\"./wrangling_data/editing_column_names.html\", target=\"_blank\">We cleaned up the column names in this article.</a>\n",
    "- Now to finish the the final step to accomplish the goal below.\n",
    "## Goal: To get each row to represent the week performance of a song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>track</th>\n",
       "      <th>time</th>\n",
       "      <th>genre</th>\n",
       "      <th>entered</th>\n",
       "      <th>peaked</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Destiny's Child</td>\n",
       "      <td>Independent Women Part I</td>\n",
       "      <td>3:38</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2000-09-23</td>\n",
       "      <td>2000-11-18</td>\n",
       "      <td>78</td>\n",
       "      <td>63.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year           artist                     track  time genre     entered  \\\n",
       "0  2000  Destiny's Child  Independent Women Part I  3:38  Rock  2000-09-23   \n",
       "\n",
       "       peaked   1     2     3 ...  67  68  69  70  71  72  73  74  75  76  \n",
       "0  2000-11-18  78  63.0  49.0 ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "\n",
       "[1 rows x 83 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/billboard_weeks_edited.csv')\n",
    "df = pd.DataFrame(data)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317, 83)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the shape of the dataset we're starting with.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that we have 317 rows and 83 columns. If we are \"unpivoting\" this to be fewer columns we can expect the rows to increase substantially. Remember this for when we check the shape again later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melt its face off!\n",
    "We will use the \".melt\" function to accomplish what we need for this dataset. More information on it can be found in the <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.melt.html\", target=\"_blank\"> documentation here.</a>\n",
    "\n",
    "### Notes on pd.melt\n",
    "First off we see that it is not applied to a dataframe, so we don't do \"df.melt\" it actually gets passed the entire dataframe object as an argument and is called by starting with \"pd.\"\n",
    "```python\n",
    "pd.melt(df)\n",
    "```\n",
    "\n",
    "## Create a new dataframe\n",
    "Simply for the ease of still being able to track back to our original csv in case something doesn't work. We will then declare a new dataframe that will take on the results of the pd.melt( ) function.\n",
    "```python\n",
    "df2 = pd.melt(df)\n",
    "```\n",
    "\n",
    "## id_vars=[ ]\n",
    "We already passed the dataframe. The id_vars argument will be the columns that will be retained in the dataframe so we'll declare that by listing the columns we want to keep. Note that this argument is taking on a list so we can pass the columns to it with all the columns list methods that we know. For this example i'll just list out the columns since there are so few.\n",
    "```python\n",
    "df2 = pd.melt(df, id_vars=['year', 'artist', 'track', 'time', 'genre', 'entered', 'peaked'])\n",
    "```\n",
    "## value_vars=[ ]\n",
    "This argument says it is for stating all the columns to \"unpivot\". Phew, we have a lot of weeks... do we have to list them all? That's the beauty of this function. If we simply leave this blank it will default to unpivot all of the columns that are not listed in the \"id_vars=[ ]\" argument. SWEET!!!\n",
    "## var_name=[ ]\n",
    "So we have this tricky thing to do with unpivoting... we'll have all the week columns get turned into row cells and they will need a column header. To do this we declare the \"var_name=[ ]\" argument with the column header we want.\n",
    "```python\n",
    "df2 = pd.melt(df, id_vars=['year', 'artist', 'track', 'time', 'genre', 'entered', 'peaked'], var_name='week')\n",
    "```\n",
    "## value_name[ ]\n",
    "Now what about all the values that are listed in each week column right now? Where are those supposed to go? Glad you asked that. These are the values that we are \"unpivoting\" but they to will need a column header since we just took the week columns away. We know that those values represent the weekly ranking of a song during that week so we'll \"unpivot\" those values to a new column called \"rank\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.melt(df, id_vars=['year', 'artist', 'track', 'time', 'genre', 'entered', 'peaked'],\n",
    "              var_name='week', value_name='rank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>track</th>\n",
       "      <th>time</th>\n",
       "      <th>genre</th>\n",
       "      <th>entered</th>\n",
       "      <th>peaked</th>\n",
       "      <th>week</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Destiny's Child</td>\n",
       "      <td>Independent Women Part I</td>\n",
       "      <td>3:38</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2000-09-23</td>\n",
       "      <td>2000-11-18</td>\n",
       "      <td>1</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>Santana</td>\n",
       "      <td>Maria, Maria</td>\n",
       "      <td>4:18</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2000-02-12</td>\n",
       "      <td>2000-04-08</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>Savage Garden</td>\n",
       "      <td>I Knew I Loved You</td>\n",
       "      <td>4:07</td>\n",
       "      <td>Rock</td>\n",
       "      <td>1999-10-23</td>\n",
       "      <td>2000-01-29</td>\n",
       "      <td>1</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>Madonna</td>\n",
       "      <td>Music</td>\n",
       "      <td>3:45</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2000-08-12</td>\n",
       "      <td>2000-09-16</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>Aguilera, Christina</td>\n",
       "      <td>Come On Over Baby (All I Want Is You)</td>\n",
       "      <td>3:38</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2000-08-05</td>\n",
       "      <td>2000-10-14</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year               artist                                  track  time  \\\n",
       "0  2000      Destiny's Child               Independent Women Part I  3:38   \n",
       "1  2000              Santana                           Maria, Maria  4:18   \n",
       "2  2000        Savage Garden                     I Knew I Loved You  4:07   \n",
       "3  2000              Madonna                                  Music  3:45   \n",
       "4  2000  Aguilera, Christina  Come On Over Baby (All I Want Is You)  3:38   \n",
       "\n",
       "  genre     entered      peaked week  rank  \n",
       "0  Rock  2000-09-23  2000-11-18    1  78.0  \n",
       "1  Rock  2000-02-12  2000-04-08    1  15.0  \n",
       "2  Rock  1999-10-23  2000-01-29    1  71.0  \n",
       "3  Rock  2000-08-12  2000-09-16    1  41.0  \n",
       "4  Rock  2000-08-05  2000-10-14    1  57.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cool! It worked!\n",
    "We now have the rows representing the lowest level of data in our dataset. What did this do to the shape of our table? Remember what it was at the beginning? Lets check it again to see what happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24092, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Woah. That is MUCH longer.\n",
    "Nothing to worry about though. You'll find that pandas can handle this length of a data table easily. Most importantly we have our dataset setup in a way where we can work with it much better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
